{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MobileNetV2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTMD2GROO_B1",
        "colab_type": "text"
      },
      "source": [
        "Welcome to jupyter notebook of MobileNetV2 in Tensorflow</br>\n",
        "* I have kept this code modular and all in one notebook</br>\n",
        "* I hope this will facilitate fast swapping of datasets and preprocessing</br>\n",
        "* For this network it is very important to use tf 1.x in colab </br>\n",
        "* But because of this generality,architecture maybe not not best for your usecase</br>\n",
        "* Modifying architecture is tweak in some hyper parameters (i'm not saying finding best of these tweaks is easy)\n",
        "* Using MobileNetV2 is bit of a overkill for such an easy task but ,..\n",
        "* This Repo will act as starting point for more complex datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZcQmymsTVWu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "16897c77-9362-4e9b-93ee-104bbf1d7711"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruqDBcAoRx7q",
        "colab_type": "text"
      },
      "source": [
        "* First step would always be preprocessing dataset here i'm using [Emnist](https://www.tensorflow.org/datasets/catalog/emnist)\n",
        "* I have to expand channels because of monochrome dataset .\n",
        "* This preprocessing will be same for FMnist and Mnist\n",
        "* But you might not need this step for RGB datasets (e.g Cifar)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ShQ1VL-Rvel",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "import h5py\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, CSVLogger, LearningRateScheduler\n",
        "from datetime import datetime\n",
        "import emnist as em\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# set meta params\n",
        "batch_size = 256\n",
        "nb_classes = 27\n",
        "nb_epoch   = 5\n",
        "nb_data    = 28*28\n",
        "\n",
        "# set meta info\n",
        "log_dir         = '/content/mobilenetV2-cifar/train_log/mobilenet_v2-like_log'\n",
        "dataset_dir     = '/content/mobilenetV2-cifar/datasets/dataset_norm'\n",
        "model_name      = 'mobilenet_v2-like__' + datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
        "model_arch_path = os.path.join(log_dir, (model_name + '_arch.png'))\n",
        "model_cp_path   = os.path.join(log_dir, (model_name + '_checkpoint.h5'))\n",
        "model_csv_path  = os.path.join(log_dir, (model_name + '_csv.csv'))\n",
        "\n",
        "(trainX, trainY) = em.extract_training_samples('letters')\n",
        "(testX, testY) = em.extract_test_samples('letters')\n",
        "# reshape dataset to have a single channel\n",
        "#(trainX,trainY),(testX,testY)=load_data()\n",
        "\n",
        "print(\"Shape of training set before concatenate :\",trainX.shape)\n",
        "trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
        "# one hot encode target values\n",
        "trainY = to_categorical(trainY)\n",
        "testY = to_categorical(testY)\n",
        "trainX = trainX.astype('float32')\n",
        "testX = testX.astype('float32')\n",
        "# normalize to range 0-1\n",
        "trainX = trainX / 255.0\n",
        "testX = testX / 255.0\n",
        "\n",
        "# load data\n",
        "#DF = DataFeeder(dataset_dir)\n",
        "X_train, y_train, X_test, y_test = trainX,trainY ,testX,testY#DF.X_train, DF.y_train, DF.X_test, DF.y_test\n",
        "\n",
        "# data augumatation\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False, \n",
        "        featurewise_std_normalization=False, \n",
        "        rotation_range=0.0,\n",
        "        width_shift_range=0.2, \n",
        "        height_shift_range=0.2, \n",
        "        vertical_flip=False,\n",
        "        horizontal_flip=True)\n",
        "datagen.fit(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfDKxpzgTejf",
        "colab_type": "text"
      },
      "source": [
        "* The Building blocks of model are defined here </br>\n",
        "* If you are totally unaware of MobileNet or DepthWise convolutions\n",
        "* Start with this great video i found on Youtube :- [link](https://www.youtube.com/watch?v=T7o3xvJLuHk)\n",
        "* You should comment out layers if you want to decrease the depth .\n",
        "* Also change the number of filters if you want to change the width\n",
        "* You can share if you find better hyper parameters for different datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjWZOUjuTftW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import warnings\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Input, Activation, Conv2D, Dense, Dropout, BatchNormalization, ReLU, DepthwiseConv2D, GlobalAveragePooling2D, GlobalMaxPooling2D, Add\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# define the filter size\n",
        "def _make_divisible(v, divisor, min_value=None):\n",
        "    if min_value is None:\n",
        "        min_value = divisor\n",
        "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
        "    # Make sure that round down does not go down by more than 10%.\n",
        "    if new_v < 0.9 * v:\n",
        "        new_v += divisor\n",
        "    return new_v\n",
        "\n",
        "\n",
        "# define the calcuration of each 'Res_Block'\n",
        "def _inverted_res_block(inputs, expansion, stride, alpha, filters, block_id):\n",
        "    prefix = 'block_{}_'.format(block_id)\n",
        "\n",
        "    in_channels = inputs.shape[-1]\n",
        "    pointwise_conv_filters = int(filters * alpha)\n",
        "    pointwise_filters = _make_divisible(pointwise_conv_filters, 8)\n",
        "    x = inputs\n",
        "\n",
        "    # Expand\n",
        "    if block_id:\n",
        "        x = Conv2D(expansion * in_channels, kernel_size=1, strides=1, padding='same', use_bias=False, activation=None, kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(4e-5), name=prefix + 'expand')(x)\n",
        "        x = BatchNormalization(epsilon=1e-3, momentum=0.999, name=prefix + 'expand_BN')(x)\n",
        "        x = ReLU(6., name=prefix + 'expand_relu')(x)\n",
        "    else:\n",
        "        prefix = 'expanded_conv_'\n",
        "\n",
        "    # Depthwise\n",
        "    x = DepthwiseConv2D(kernel_size=3, strides=stride, activation=None, use_bias=False, padding='same', kernel_initializer=\"he_normal\", depthwise_regularizer=regularizers.l2(4e-5), name=prefix + 'depthwise')(x)\n",
        "    x = BatchNormalization(epsilon=1e-3, momentum=0.999, name=prefix + 'depthwise_BN')(x)\n",
        "    x = ReLU(6., name=prefix + 'depthwise_relu')(x)\n",
        "\n",
        "    # Project\n",
        "    x = Conv2D(pointwise_filters, kernel_size=1, strides=1, padding='same', use_bias=False, activation=None, kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(4e-5), name=prefix + 'project')(x)\n",
        "    x = BatchNormalization(epsilon=1e-3, momentum=0.999, name=prefix + 'project_BN')(x)\n",
        "\n",
        "\n",
        "    if in_channels == pointwise_filters and stride == 1:\n",
        "        return Add(name=prefix + 'add')([inputs, x])\n",
        "    return x\n",
        "\n",
        "# build MobileNetV2 models\n",
        "def MobileNetV2(input_shape=(28, 28, 1),\n",
        "                alpha=1.0,\n",
        "                depth_multiplier=1,\n",
        "                include_top=True,\n",
        "                pooling=None,\n",
        "                classes=27):\n",
        "\n",
        "    # fileter size (first block)\n",
        "    first_block_filters = _make_divisible(32 * alpha, 8)\n",
        "    # input shape  (first block)\n",
        "    img_input = Input(shape=input_shape)\n",
        "\n",
        "    # model architechture\n",
        "    x = Conv2D(first_block_filters, kernel_size=3, strides=1, padding='same', use_bias=False, kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(4e-5), name='Conv1')(img_input)\n",
        "    #x = BatchNormalization(epsilon=1e-3, momentum=0.999, name='bn_Conv1')(x)\n",
        "    #x = ReLU(6., name='Conv1_relu')(x)\n",
        "\n",
        "    x = _inverted_res_block(x, filters=16,  alpha=alpha, stride=1, expansion=1, block_id=0 ) # O/p 28x28\n",
        "\n",
        "    x = _inverted_res_block(x, filters=24,  alpha=alpha, stride=1, expansion=6, block_id=1 ) # O/p 28x28\n",
        "    x = _inverted_res_block(x, filters=24,  alpha=alpha, stride=1, expansion=6, block_id=2 ) # O/p 28x28\n",
        "\n",
        "    x = _inverted_res_block(x, filters=32,  alpha=alpha, stride=2, expansion=6, block_id=3 ) # O/p 14x14\n",
        "    x = _inverted_res_block(x, filters=32,  alpha=alpha, stride=1, expansion=6, block_id=4 ) # O/p 14x14\n",
        "    x = _inverted_res_block(x, filters=32,  alpha=alpha, stride=1, expansion=6, block_id=5 ) # O/p 14x14\n",
        "\n",
        "    x = _inverted_res_block(x, filters=64,  alpha=alpha, stride=2, expansion=6, block_id=6 ) # O/p 7x7\n",
        "    x = _inverted_res_block(x, filters=64,  alpha=alpha, stride=1, expansion=6, block_id=7 ) # O/p 7x7\n",
        "    x = _inverted_res_block(x, filters=64,  alpha=alpha, stride=1, expansion=6, block_id=8 ) # O/p 7x7\n",
        "    x = _inverted_res_block(x, filters=64,  alpha=alpha, stride=1, expansion=6, block_id=9 ) # O/p 7x7\n",
        "    x = Dropout(rate=0.25)(x)\n",
        "\n",
        "    # x = _inverted_res_block(x, filters=96,  alpha=alpha, stride=1, expansion=6, block_id=10)\n",
        "    # x = _inverted_res_block(x, filters=96,  alpha=alpha, stride=1, expansion=6, block_id=11)\n",
        "    # x = _inverted_res_block(x, filters=96,  alpha=alpha, stride=1, expansion=6, block_id=12)\n",
        "    # x = Dropout(rate=0.25)(x)\n",
        "\n",
        "    # x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1, expansion=6, block_id=13) # O/p 7x7\n",
        "    # x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1, expansion=6, block_id=14) # O/p 7x7\n",
        "    # x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1, expansion=6, block_id=15) # O/p 7x7\n",
        "    # x = Dropout(rate=0.25)(x)\n",
        "\n",
        "    x = _inverted_res_block(x, filters=128, alpha=alpha, stride=1, expansion=6, block_id=16)\n",
        "    x = Dropout(rate=0.25)(x)\n",
        "\n",
        "    # define fileter size (last block)\n",
        "    if alpha > 1.0:\n",
        "        last_block_filters = _make_divisible(256 * alpha, 8)\n",
        "    else:\n",
        "        last_block_filters = 256\n",
        "\n",
        "\n",
        "    x = Conv2D(last_block_filters, kernel_size=1, use_bias=False, kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(4e-5), name='Conv_1')(x)\n",
        "    x = BatchNormalization(epsilon=1e-3, momentum=0.999, name='Conv_1_bn')(x)\n",
        "    x = ReLU(6., name='out_relu')(x)\n",
        "    \n",
        "    # top layer (\"use\" or \"not use\" FC)\n",
        "    if include_top:\n",
        "        x = GlobalAveragePooling2D(name='global_average_pool')(x)\n",
        "        x = Dense(classes, activation='softmax', use_bias=True, name='Logits')(x)\n",
        "    else:\n",
        "        if pooling == 'avg':\n",
        "            x = GlobalAveragePooling2D()(x)\n",
        "        elif pooling == 'max':\n",
        "            x = GlobalMaxPooling2D()(x)\n",
        "\n",
        "    # create model of MobileNetV2 (for CIFAR-10)\n",
        "    model = Model(inputs=img_input, outputs=x, name='mobilenetv2_cifar10')\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "# build model\n",
        "model = MobileNetV2(input_shape=X_train.shape[1:], include_top=True, alpha=1.0)\n",
        "model.summary()\n",
        "print('Model Name: ', model_name)\n",
        "\n",
        "# save model architechture plot (.png)\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model, to_file=model_arch_path, show_shapes=True)\n",
        "\n",
        "\n",
        "# set learning rate\n",
        "learning_rates=[]\n",
        "for i in range(5):\n",
        "    learning_rates.append(2e-2)\n",
        "for i in range(50-5):\n",
        "    learning_rates.append(1e-2)\n",
        "for i in range(100-50):\n",
        "    learning_rates.append(8e-3)\n",
        "for i in range(150-100):\n",
        "    learning_rates.append(4e-3)\n",
        "for i in range(200-150):\n",
        "    learning_rates.append(2e-3)\n",
        "for i in range(300-200):\n",
        "    learning_rates.append(1e-3)\n",
        "\n",
        "# set callbacks\n",
        "callbacks = []\n",
        "#callbacks.append(TensorBoard(log_dir=log_dir, histogram_freq=1))\n",
        "callbacks.append(ModelCheckpoint(model_cp_path, monitor='val_loss', save_best_only=True))\n",
        "callbacks.append(LearningRateScheduler(lambda epoch: float(learning_rates[epoch])))\n",
        "callbacks.append(CSVLogger(model_csv_path)) \n",
        "\n",
        "# compile & learning model #Note Currenly ive used default SGD\n",
        "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "history = model.fit_generator(\n",
        "              datagen.flow(X_train, y_train, batch_size=batch_size),\n",
        "              steps_per_epoch=len(X_train) / batch_size,\n",
        "              epochs=30,\n",
        "              verbose=1,\n",
        "              callbacks=callbacks,\n",
        "              validation_data=(X_test, y_test))\n",
        "   \n",
        "# validation\n",
        "val_loss, val_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Model Name: ', model_name)\n",
        "print('Test loss     : {:.5f}'.format(val_loss))\n",
        "print('Test accuracy : {:.5f}'.format(val_acc))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lviyDIlbZgh8",
        "colab_type": "text"
      },
      "source": [
        "Save the full model all at once"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpz9Cx0A6F1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('MobileNetV2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}